{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dtypesBvot = {\n",
    "    'NUMTOUR' :    'int64',\n",
    "    'CODDPT' :    'object',\n",
    "    'CODSUBCOM' :  'int64',\n",
    "    'LIBSUBCOM' : 'object',\n",
    "    'CODBURVOT' : 'object',\n",
    "    'CODCAN' :     'int64',\n",
    "    'LIBCAN' :    'object',\n",
    "    'NBRINS' :     'int64',\n",
    "    'NBRVOT' :     'int64',\n",
    "    'NBREXP' :     'int64',\n",
    "    'NUMDEPCAND' : 'int64',\n",
    "    'LIBLISEXT' : 'object',\n",
    "    'CODNUA' :    'object',\n",
    "    'NBRVOIX' :    'int64',\n",
    "}\n",
    "\n",
    "departements = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', \n",
    "                '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', \n",
    "                '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', \n",
    "                '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '76', '77', '78', \n",
    "                '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95']\n",
    "\n",
    "################################# Load data #################################\n",
    "def loadDatas(dataPaths, sep=';', dtype=dtypesBvot, col_dep='CODDPT', col_tour='NUMTOUR'):\n",
    "    dataT1Bvot = pd.DataFrame()\n",
    "    dataT2Bvot = pd.DataFrame()\n",
    "    for path in dataPaths:\n",
    "        dataBvot = pd.read_csv(path, sep=sep, dtype=dtype)\n",
    "        dataBvot = dataBvot[dataBvot[col_dep].isin(departements)]\n",
    "        dataT1Bvot = pd.concat([dataT1Bvot ,dataBvot[dataBvot[col_tour]==1]])\n",
    "        dataT2Bvot = pd.concat([dataT2Bvot ,dataBvot[dataBvot[col_tour]==2]])\n",
    "\n",
    "    return dataT1Bvot, dataT2Bvot\n",
    "\n",
    "################################# fonction utile #############################\n",
    "def saveData(data, loc):\n",
    "    # save cher_data as excel\n",
    "    writer = pd.ExcelWriter(loc)\n",
    "    \n",
    "    # write dataframe to excel\n",
    "    data.to_excel(writer)\n",
    "\n",
    "    # save the excel\n",
    "    writer.save()\n",
    "\n",
    "\n",
    "\n",
    "############################# Format des donnees brute ##############################\n",
    "\n",
    "def getNbBinomes(data):\n",
    "    return len([header for header in data.columns if \"Binôme\" in header])\n",
    "\n",
    "def explodeLines(data):\n",
    "    initdf = data[['Code du département', 'Libellé du département', 'Code du canton', \n",
    "            'Libellé du canton', 'Inscrits', 'Abstentions', '% Abs/Ins', 'Votants',\n",
    "            '% Vot/Ins', 'Blancs', '% Blancs/Ins', '% Blancs/Vot', 'Nuls', '% Nuls/Ins',\n",
    "            '% Nuls/Vot', 'Exprimés', '% Exp/Ins', '% Exp/Vot']]\n",
    "\n",
    "    headers = ['N°Panneau', 'Nuance', 'Binôme', 'Sièges', 'Voix', '% Voix/Ins', '% Voix/Exp']\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for i in range(getNbBinomes(data)):\n",
    "        partidf = data[[h+'.'+str(i) if i!=0 else h for h in headers]]\n",
    "        partidf = pd.concat([initdf, partidf], axis=1)\n",
    "        partidf.columns = pd.Index(initdf.columns.values.tolist() + headers)\n",
    "        df = pd.concat([df, partidf])\n",
    "    \n",
    "    # Remove useless rows   \n",
    "    df = df.dropna(how='all', subset=headers)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadDataPath = ['../dataset/raw/DP15_Bvot_T1T2.csv']\n",
    "\n",
    "#load data\n",
    "dataT1Bvot, dataT2Bvot = loadDatas(loadDataPath)\n",
    "\n",
    "assert dataT1Bvot.shape != (0,0) and dataT2Bvot.shape != (0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionnaire des duels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### Dictionnaire des duels #####################################\n",
    "\n",
    "def getNuanceOfElected(data, col_siege='Sièges', col_nuance='Nuance'):\n",
    "    elected = data[data[col_siege]=='Elus']\n",
    "    return list(elected[col_nuance]) if len(elected)!=0 else None\n",
    "\n",
    "def filterBestNuances(data, col_nuance='Nuance', criteria=12.50):\n",
    "    bestCandidat = data[data['% Voix/Ins']>= criteria]\n",
    "    \n",
    "    if bestCandidat.empty or len(bestCandidat)==1:\n",
    "        bestCandidat = data.sort_values(by='Voix', ascending=False).iloc[0:2,:]\n",
    "\n",
    "    return list(bestCandidat[col_nuance])\n",
    "\n",
    "def getDuelsFromDep(data_dep, col_dep='CODDPT', col_canton='CODCAN', col_nuance='CODNUA'):\n",
    "    '''\n",
    "        return : {'canton_1':[P1,...,P_k], ..., 'canton_n':[P1,...,P_K]}, \n",
    "                                        ..., \n",
    "                    'canton_N':[P1,...,P_i], ..., 'canton_m':[P1,...,P_I]}\n",
    "                  }\n",
    "    '''\n",
    "    duels = dict()\n",
    "    for canton in data_dep[col_canton].unique():\n",
    "        data_canton = data_dep[data_dep[col_canton]==canton]\n",
    "        duels[str(canton)]= list(data_canton[col_nuance].unique())\n",
    "    return duels \n",
    "\n",
    "def optimizedDuelDict(duels):\n",
    "    '''\n",
    "        return : {'duel_1':{'dep':[canton],..., 'duel_n':[canton]},\n",
    "                            ...,\n",
    "                  'duel_N':{'dep':[canton],..., 'duel_n':[canton]}\n",
    "                  }\n",
    "            avec :\n",
    "                  - duel = 'P1:P2:...:Pn'\n",
    "    '''\n",
    "    optdict = dict()\n",
    "    for dep, duelDepDict in duels.items():\n",
    "        for canton, duelList in duelDepDict.items():\n",
    "            key = ':'.join(sorted(duelList))\n",
    "            if key in optdict.keys():                \n",
    "                if dep in optdict[key].keys():\n",
    "                    optdict[key][dep].append(int(canton))\n",
    "                else:\n",
    "                    optdict[key][dep]=[int(canton)]\n",
    "            else:\n",
    "                optdict[key]= dict([(dep, [int(canton)])])\n",
    "    return optdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dictionnaire des duels\n",
    "duels = dict()\n",
    "for dep in dataT2Bvot['CODDPT'].unique():\n",
    "    duels[str(dep)]= getDuelsFromDep(dataT2Bvot[dataT2Bvot['CODDPT']==dep])\n",
    "    if duels[str(dep)]==[]:\n",
    "        print('empty list for dep : ', dep)\n",
    "\n",
    "#dictionnaire optimize\n",
    "optDuels = optimizedDuelDict(duels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(optDuels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation des donnees et entrainement du reseau de neuronne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### Data Processing ####################################\n",
    "\n",
    "def prepareInputDataExploded(data):\n",
    "    tmp = data[['NUMTOUR', 'CODDPT', 'CODSUBCOM', 'LIBSUBCOM', 'CODBURVOT', 'CODCAN',\n",
    "            'LIBCAN', 'NBRINS', 'NBRVOT', 'NBREXP', 'CODNUA', 'NBRVOIX']].copy()\n",
    "\n",
    "    # Compute missing data\n",
    "    tmp['NBRABS'] = tmp['NBRINS'] - tmp['NBRVOT']\n",
    "    tmp['NBRBLCNUL'] = tmp['NBRVOT'] - tmp['NBREXP']\n",
    "    tmp['%ABS/INS'] = tmp['NBRABS'] / tmp['NBRINS']\n",
    "    tmp['%BLCNUL/VOT'] = tmp['NBRBLCNUL'] / tmp['NBRVOT']\n",
    "    tmp['%EXP/VOT'] = tmp['NBREXP'] / tmp['NBRVOT']\n",
    "    tmp['%VOIX/EXP'] = tmp['NBRVOIX'] / tmp['NBREXP']\n",
    "\n",
    "    nuances = getAllNuances()\n",
    "    statsFeatures = ['NBRINS', 'NBREXP', '%ABS/INS', '%BLCNUL/VOT', '%EXP/VOT']\n",
    "    idFeatures = ['CODDPT', 'CODCAN', 'CODSUBCOM', 'CODBURVOT']\n",
    "\n",
    "    exprimes = tmp[idFeatures + ['NBREXP']].drop_duplicates().sort_values(idFeatures)['NBREXP']\n",
    "    stats = tmp[idFeatures + statsFeatures].drop_duplicates()[statsFeatures]\n",
    "    ids = tmp[idFeatures].drop_duplicates()\n",
    "\n",
    "    # Create [%Voix] and fill it\n",
    "    voix = pd.DataFrame(0, index=data.index, columns=nuances)\n",
    "    for parti in data.CODNUA.unique():\n",
    "        voix[parti][data['CODNUA']==parti] = tmp[tmp['CODNUA']==parti]['NBRVOIX']\n",
    "    voix = pd.concat([tmp[idFeatures], voix], axis=1).groupby(idFeatures).sum()[nuances]\n",
    "    voix.index = exprimes.index\n",
    "\n",
    "    # Concat with computed stats and divide almost everything by Exprimés\n",
    "    voix = voix.divide(exprimes, axis=0)\n",
    "    X = pd.concat([stats, voix], axis=1)\n",
    "    X.index = pd.MultiIndex.from_frame(ids)\n",
    "    return X.sort_values(['CODDPT', 'CODCAN', 'CODSUBCOM', 'CODBURVOT']).fillna(0)\n",
    "\n",
    "def getAllNuances(data=dataT1Bvot, colNuance='CODNUA', fmt='exploded'):\n",
    "    if fmt not in ['exploded', 'line']:\n",
    "        raise ValueError(\"format parameter must be 'exploded' or 'line'\")\n",
    "    \n",
    "    if fmt == 'exploded':\n",
    "        nuances = data[colNuance].unique()\n",
    "    \n",
    "    if fmt == 'line':\n",
    "        nuances = np.array([])\n",
    "        nuances_tmp = data[colNuance].fillna(0)\n",
    "        for c in nuances_tmp:\n",
    "            nuances = np.append(nuances, nuances_tmp[c])\n",
    "        nuances = np.unique(nuances[nuances!=0])\n",
    "    \n",
    "    return sorted(nuances)\n",
    "\n",
    "# retourne un dataset associe a un duel\n",
    "def extractDuelRaw(duel, X=dataT1Bvot, y=dataT2Bvot, col_canton='CODCAN', col_dep='CODDPT'):\n",
    "    correction = [str(i) for i in range(1,10)]\n",
    "    X_duel = pd.DataFrame()\n",
    "    y_duel = pd.DataFrame()\n",
    "\n",
    "    #remove canton where there is a winner in the 1st turn\n",
    "    for dep, cantonList in optDuels[':'.join(sorted(duel))].items():\n",
    "        X_duel = pd.concat([X_duel, X.loc[( X[col_dep] == (dep if dep not in correction else '0'+dep) ) & ( X[col_canton].isin(cantonList) )]])\n",
    "        y_duel = pd.concat([y_duel, y.loc[( y[col_dep] == (dep if dep not in correction else '0'+dep) ) & ( y[col_canton].isin(cantonList) )]])\n",
    "    \n",
    "    return (X_duel, y_duel)\n",
    "\n",
    "def prepareLabelsExploded(data, oneHotEncode=False):\n",
    "    nuances = getAllNuances(data)\n",
    "    idFeatures = ['CODDPT', 'CODCAN', 'CODSUBCOM', 'CODBURVOT']\n",
    "\n",
    "    exprimes = data[idFeatures+['NBREXP']].groupby(idFeatures).first()\n",
    "\n",
    "    # Create [%Voix] and fill it\n",
    "    voix = pd.DataFrame(0, index=data.index, columns=nuances)\n",
    "    for parti in nuances:\n",
    "        voix[parti][data['CODNUA']==parti] = data[data['CODNUA']==parti]['NBRVOIX']\n",
    "    voix = pd.concat([data[idFeatures], voix], axis=1).groupby(idFeatures).sum().sort_values(idFeatures)[nuances]\n",
    "\n",
    "    # Concat with computed stats and divide voix by exprimes\n",
    "    y = voix.divide(exprimes['NBREXP'], axis=0)\n",
    "    return y.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "def testna(data):\n",
    "    return len(data[data.isna().any(axis=1)])\n",
    "\n",
    "\n",
    "def getTestAccuracy(duel):\n",
    "    return models[duel]['accuracy'][1]\n",
    "\n",
    "def getTrainAccuracy(duel):\n",
    "    return models[duel]['accuracy'][0]\n",
    "\n",
    "def getActivation(duel):\n",
    "    return models[duel]['activation']\n",
    "\n",
    "def getLoss(duel):\n",
    "    return models[duel]['loss']\n",
    "\n",
    "def getHistory(duel):\n",
    "    return models[duel]['history']\n",
    "\n",
    "def getModel(duel):\n",
    "    return models[duel]['model']\n",
    "\n",
    "def getDataset(duel):\n",
    "    return models[duel]['dataset']\n",
    "\n",
    "def criteriaRespected(test_acc, loss, test_criteria=0.55, loss_criteria=0.14):\n",
    "    return test_acc >= test_criteria and loss <=loss_criteria\n",
    "\n",
    "def betterModel(duel, test_acc, loss, epsilon=0.001):\n",
    "    current_acc = getTestAccuracy(duel)\n",
    "    current_loss = getLoss(duel)\n",
    "    return test_acc >= current_acc and loss<=current_loss + epsilon\n",
    "    \n",
    "def saveModel(model, save_name, duel):\n",
    "    model_path = 'models/'+duel+'/'+save_name\n",
    "    model.save(model_path)\n",
    "    \n",
    "\n",
    "def showPlot(history, save=False, save_name=None, duel=None):\n",
    "    # plot loss during training\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Loss')\n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='test')\n",
    "    pyplot.legend()\n",
    "    \n",
    "    # plot accuracy during training\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "    pyplot.legend()\n",
    "\n",
    "    if save:\n",
    "        if not os.path.isdir('models/'+duel):\n",
    "            os.mkdir('models/'+duel)\n",
    "            \n",
    "        fig_path = 'models/'+duel+'/'+save_name+'.png'\n",
    "        pyplot.savefig(fig_path)\n",
    "\n",
    "    pyplot.show()\n",
    "\n",
    "def getDuelData(duel):\n",
    "    #Selecting data\n",
    "    X_duel, y_duel  = extractDuelRaw(duel)\n",
    "\n",
    "    print('Preparing input data... ', end='')\n",
    "    X = prepareInputDataExploded(X_duel)\n",
    "    print('OK')\n",
    "\n",
    "    print('Preparing labels... ', end='')\n",
    "    y = prepareLabelsExploded(y_duel)\n",
    "    print('OK')\n",
    "\n",
    "    assert X.shape[0]==y.shape[0]\n",
    "    \n",
    "    if len(y.columns)<2:\n",
    "        print(\"duel with same nuance !\")\n",
    "        print(\"skipped\")\n",
    "        return (pd.DataFrame(), pd.DataFrame() )\n",
    "        \n",
    "    if testna(X_duel) or testna(y_duel) or testna(X) or testna(y):\n",
    "        print('nan in X_duel', testna(X_duel))\n",
    "        print('nan in y_duel', testna(y_duel))\n",
    "        print('nan in X', testna(X))\n",
    "        print('nan in y', testna(y))\n",
    "\n",
    "\n",
    "    return X,y\n",
    "\n",
    "\n",
    "def configureModel(act, X=None, y=None, X_train=None, X_test=None, y_train=None, y_test=None):\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    in_shape  = (X_train.shape[1],) if X_train is not None else (X.shape[1],)\n",
    "    out_shape = y_train.shape[1] if y_train is not None else y.shape[1]\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=in_shape))\n",
    "    model.add(tf.keras.layers.Dense(32, activation=act))\n",
    "    model.add(tf.keras.layers.Dense(out_shape, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adamax', metrics=['accuracy'])\n",
    "\n",
    "    if X_train is not None and X_test is not None and y_train is not None and y_test is not None:\n",
    "        history = model.fit(X_train, y_train, batch_size=32, validation_data=(X_test, y_test), epochs=100, verbose=0)\n",
    "        _, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "        _, test_acc  = model.evaluate(X_test , y_test , verbose=0)\n",
    "    elif X is not None and y is not None:\n",
    "        history = model.fit(X, y, batch_size=32, epochs=100, verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "    return (model, train_acc, test_acc, history) if (X is None and y is None) else model\n",
    "\n",
    "def setModel(model, duel):\n",
    "    models[duel]['model'] = model\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Fake prediction ---------------------------\n",
      "Preparing input data... OK\n",
      "Preparing labels... OK\n",
      "--------------------------- prediction -------------------------\n",
      "            FN        UD\n",
      "0     0.301603  0.698397\n",
      "1     0.374333  0.625667\n",
      "2     0.197483  0.802517\n",
      "3     0.460452  0.539548\n",
      "4     0.339063  0.660937\n",
      "...        ...       ...\n",
      "2497  0.409616  0.590383\n",
      "2498  0.424450  0.575550\n",
      "2499  0.447672  0.552328\n",
      "2500  0.355609  0.644391\n",
      "2501  0.290984  0.709016\n",
      "\n",
      "[2502 rows x 2 columns]\n",
      "------------------------ y_test -----------------------------\n",
      "                                      BC-FN     BC-UD\n",
      "CODDPT CODCAN CODSUBCOM CODBURVOT                    \n",
      "56     13     165       0002       0.257764  0.742236\n",
      "76     21     740       0001       0.321608  0.678392\n",
      "72     21     127       0002       0.177570  0.822430\n",
      "34     1      3         0020       0.491124  0.508876\n",
      "59     22     152       0005       0.318538  0.681462\n",
      "...                                     ...       ...\n",
      "76     26     361       0001       0.405797  0.594203\n",
      "06     23     88        0918       0.407240  0.592760\n",
      "83     18     49        0002       0.469816  0.530184\n",
      "39     12     199       0001       0.354497  0.645503\n",
      "53     6      249       0001       0.295455  0.704545\n",
      "\n",
      "[2502 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# fake prediction\n",
    "print('--------------------------- Fake prediction ---------------------------')\n",
    "x, y = getDuelData(['BC-FN', 'BC-UD'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2,train_size=0.8, random_state=42, shuffle=True)\n",
    "model, train_acc, test_acc, history = configureModel('relu', X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "print('--------------------------- prediction -------------------------')\n",
    "print(pd.DataFrame(model.predict(X_test), columns=['FN', 'UD']))\n",
    "print('------------------------ y_test -----------------------------')\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict()\n",
    "noModel = []\n",
    "activations = ['relu', 'elu', 'selu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "################################################ Creation des modeles #######################################3\n",
    "def getBestModels(duelList, save=False, nbModel=None):\n",
    "    nbSmallDataset = 0\n",
    "    nbDataset = 0\n",
    "    i=0\n",
    "    for duel in duelList:\n",
    "        if nbModel is not None and nbModel<=i:\n",
    "            break\n",
    "        print('\\n---------------------------------------- Duel :',duel , '--------------------------------------')\n",
    "\n",
    "        i+=1\n",
    "        duel_ = sorted(duel.split(':'))\n",
    "        if len(duel_)>=2:\n",
    "            \n",
    "            X, y = getDuelData(duel_)\n",
    "\n",
    "            if X.empty and y.empty:\n",
    "                continue\n",
    "\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,train_size=0.8, random_state=42, shuffle=True)\n",
    "            assert X_train.shape[0]==y_train.shape[0] and y_test.shape[0]== X_test.shape[0]\n",
    "    \n",
    "            for act in activations:\n",
    "                model, train_acc, test_acc, history = configureModel(act, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "                loss = history.history['loss'][-1]\n",
    "\n",
    "                if criteriaRespected(test_acc, loss):\n",
    "                    # if already have a model for this duel\n",
    "                    if duel in models.keys():\n",
    "                        if betterModel(duel, test_acc, loss):\n",
    "                            # replace current model by a better one\n",
    "                            print(act, 'function is better', 'Train: %.3f, Test: %.3f loss:%.4f' % (train_acc, test_acc, loss))\n",
    "                            models[duel]= dict([('model', model)   , ('accuracy', (train_acc, test_acc)), ('loss', loss),\n",
    "                                                ('activation', act), ('history', history), ('dataset', (X,y))\n",
    "                                            ])\n",
    "                        else:\n",
    "                            print(act, 'function is not better', 'Train: %.3f, Test: %.3f loss:%.4f' % (train_acc, test_acc, loss))\n",
    "                    else:\n",
    "                        #append new model\n",
    "                        print(act, 'function used for the new model', 'Train: %.3f, Test: %.3f loss:%.4f' % (train_acc, test_acc, loss))\n",
    "                        models[duel]= dict([('model', model)   , ('accuracy', (train_acc, test_acc)), ('loss', loss),\n",
    "                                            ('activation', act), ('history', history), ('dataset', (X,y))\n",
    "                                        ])\n",
    "                        if duel in noModel:\n",
    "                            #remove the duel from the noModel list\n",
    "                            noModel.pop(noModel.index(duel))\n",
    "                else:\n",
    "                    print(act, 'funtion is worst !', 'Train: %.3f, Test: %.3f loss:%.4f' % (train_acc, test_acc, loss))\n",
    "                    if duel not in noModel+list(models.keys()):\n",
    "                        noModel.append(duel)\n",
    "                \n",
    "            if duel not in noModel:\n",
    "                if save:\n",
    "                    saveName = duel.replace(':','_') + '_train_' + f'{getTrainAccuracy(duel):.2f}'+ '_test_' + \\\n",
    "                                f'{getTestAccuracy(duel):.2f}'+'_loss_'+ f'{getLoss(duel):.4f}'\n",
    "                    \n",
    "\n",
    "                showPlot(getHistory(duel), save=save, save_name=saveName.replace('.',','), duel=duel.replace(':', '_') )\n",
    "                print('Train: %.3f, Test: %.3f loss:%.4f activation: %s' % \n",
    "                        (getTrainAccuracy(duel), getTestAccuracy(duel), getLoss(duel), getActivation(duel)))\n",
    "                \n",
    "\n",
    "            else:\n",
    "                print('no model for this duel !')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            if X_train.shape[0]<500:\n",
    "                nbSmallDataset+=1\n",
    "\n",
    "            nbDataset+=1\n",
    "                \n",
    "        \n",
    "\n",
    "    \n",
    "        print(f'shape xtrain {X_train.shape} shape ytrain {y_train.shape} || shape xtest {X_test.shape} shape ytest {y_test.shape}')\n",
    "        print('Progression..........................................................................................................', \n",
    "                f'{(i/len(duelList))*100:.2f}%')\n",
    "            \n",
    "\n",
    "\n",
    "    print(\"pourcentage de petit dataset : \", (nbSmallDataset/nbDataset)*100)\n",
    "    print('duel with no model : ', noModel)\n",
    "\n",
    "\n",
    "getBestModels(optDuels.keys(), save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to find a model for the duels with no model\n",
    "getBestModels(noModel, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model with all the dataset\n",
    "def trainFinalModels(save=False):\n",
    "    for duel in models.keys():\n",
    "        act = getActivation(duel)\n",
    "        X,y = getDataset(duel)\n",
    "        model = configureModel(act, X=X, y=y)\n",
    "        setModel(model, duel)\n",
    "        if save:\n",
    "            saveName = duel.replace(':','_') + '_train_' + f'{getTrainAccuracy(duel):.2f}'+ '_test_' + \\\n",
    "                                    f'{getTestAccuracy(duel):.2f}'+'_loss_'+ f'{getLoss(duel):.4f}'\n",
    "            saveModel(getModel(duel), saveName.replace('.',','), duel.replace(':', '_'))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFinalModels(save=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}